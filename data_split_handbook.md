# How to use our datasets?

**Author: Yucheng Liang**

**Last Updated Time: 2020-04-08**

This document illustrates the usage of our dataset from the view of client.

## Glossary

+ split data: data split by our methods(leave one item, leave one basket, ...)
+ raw data: original raw data of the dataset.
+ processed data: data that is reformatted but not split.
+ Onedrive: our team's remote drive.
+ local: client's computer

## Methods

1. `download()`: download raw data with a URL.
2. `make_xxx()`: generate split data and store them locally.
3. `load_xxx()`: load split data from local disk or from Onedrive.

## Scenario

1. For those datasets that can be download with a URL:

   a. download raw data and store in local.

   b. load_xxx: if the data is not existed locally, download data with default parameters from Onedrive.

   c. make_xxx: split data based on processed data and store them locally.

2. For those datasets that must be download by client manurally:

   a. download manurally from website and move to the specified folder.

   b-c: the same as the 1.

## Difference between load and make

`load_xxx`:

+ pros:
  + This method do not need any computational resource of local machine if the client is requesting the default data. Client can access split data easily by downloading from our Onedrive.
  + For those who want to run on PC, this is faster.
+ cons:
  + The split data is split by us in advanced with specified parameters(e.g, test_rate, random), the user cannot specify parameters when using this methods. But it sometimes could be a pros because novice can use the default data easily.
  + Occupy some local storage.

`make_xxx`:

+ pros: 
  + Allow client to specify some parameters when spliting data, more flexible for experienced users.
  + Client can specify whether to store the result locally. If not, this method can save a huge amount of storage.
+ cons:
  + It may use client's computational resource.

## Thoughts on Dataset Path

Basically, we are supposed to store all dataset data in the `./datasets` folder. e.g,

```
-|
  - datasets
  	- ml_100k
  	- ml_1m
  	- ml_25m
```

For each dataset, we store the original data in `raw` folder and store the processed data in `processed` folder. Use `movielens_100k` as an example:

```
-|
  - raw
  	- ml-100k
  	ml-100k.zip
  - processed
  	ml_100k_interaction.npz
  	- /temporal/
  	- /temporal_basket/
  	
```

For each split method, we'd like to store their parameters in the path name. The parameters include `test_rate`, `random`, `n_negative`, `by_user` and so on. For example, leave_one_out(test_rate=0.1, random=False, n_negative=2, by_user=False, test_copy=10). The directory should be 

```
/leave_one_out/
```

### save parameters in file path

Because we may store files that are generated by the same split method but with different parameters, we'd like to store pararmeters in the file path so as to differentiate them.

We encode the parameters into the file path as string with the following format.

```
[test_rate]_[random]_[n_negative]_[by_user]_[test_copy]
```

For example, `temporal_split(self, test_rate=0.1, n_negative=2, by_user=False, test_copy=10)`, the path should be:

```
010_0_2_0_10
```

